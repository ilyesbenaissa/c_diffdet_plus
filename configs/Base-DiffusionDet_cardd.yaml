MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  
  # --- ADDED for CarDD ---
  # This sets the number of classes for your specific dataset.
  DiffusionDet:
    NUM_CLASSES: 6

  ROI_HEADS:
    IN_FEATURES: ["p2", "p3", "p4", "p5"]
    # --- ADDED for CarDD ---
    NUM_CLASSES: 6 # This must be 6 for the CarDD dataset.

  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2

# --- ADDED for CarDD ---
# This section tells the trainer which dataset to use.
DATASETS:
  TRAIN: ("carDD_train",)
  TEST: ("carDD_val",)

SOLVER:
  # --- MODIFIED for CarDD (Recommended) ---
  IMS_PER_BATCH: 4 # Lowered batch size in case of memory issues.
  BASE_LR: 0.00025
  STEPS: (15000, 18000)      # MODIFIED for a shorter training schedule
  MAX_ITER: 100000             # MODIFIED for a smaller dataset
  CHECKPOINT_PERIOD: 5000     # ADDED to save checkpoints periodically
  # ------------------------------------
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 1.0  # keep same with BASE_LR.
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

SEED: 40244023

INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: False
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"

TEST:
  EVAL_PERIOD: 1000 # MODIFIED to evaluate more frequently on a shorter run

DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4

# --- ADDED for CarDD ---
# This creates a new folder for your model's outputs.
OUTPUT_DIR: ./output_carDD

VERSION: 2